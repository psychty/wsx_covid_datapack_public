#           Max_change_week = max(Change_actual_by_week, na.rm =TRUE)) %>%
# mutate(Max_rolling_rate = ifelse(Max_rolling_rate <= 50, round_any(Max_rolling_rate, 5, ceiling), ifelse(Max_rolling_rate <= 100, round_any(Max_rolling_rate, 10, ceiling), ifelse(Max_rolling_rate <= 250, round_any(Max_rolling_rate, 25, ceiling), ifelse(Max_rolling_rate <= 500, round_any(Max_rolling_rate, 50, ceiling), ifelse(Max_rolling_rate <= 1000, round_any(Max_rolling_rate, 100, ceiling),  round_any(Max_rolling_rate, 200, ceiling))))))) %>%   mutate(Max_change_week = ifelse(Max_change_week <= 10, round_any(Max_change_week, 1, ceiling), ifelse(Max_change_week <= 20, round_any(Max_change_week, 2, ceiling), ifelse(Max_change_week <= 50, round_any(Max_change_week, 5, ceiling), round_any(Max_change_week, 10, ceiling))))) %>%
#   toJSON() %>%
#   write_lines(paste0(output_directory_x,'/utla_growth_limits.json'))
# growth_rate_utla %>%
#   filter(Date == complete_date) %>%
#   summarise(Max_rolling_rate = max(Rolling_7_day_rate, na.rm = TRUE),
#             Max_change_week = max(Change_actual_by_week, na.rm =TRUE)) %>%
#     mutate(Max_rolling_rate = ifelse(Max_rolling_rate <= 50, round_any(Max_rolling_rate, 5, ceiling), ifelse(Max_rolling_rate <= 100, round_any(Max_rolling_rate, 10, ceiling), ifelse(Max_rolling_rate <= 250, round_any(Max_rolling_rate, 25, ceiling), ifelse(Max_rolling_rate <= 500, round_any(Max_rolling_rate, 50, ceiling), ifelse(Max_rolling_rate <= 1000, round_any(Max_rolling_rate, 100, ceiling),  round_any(Max_rolling_rate, 200, ceiling))))))) %>%   mutate(Max_change_week = ifelse(Max_change_week <= 10, round_any(Max_change_week, 1, ceiling), ifelse(Max_change_week <= 20, round_any(Max_change_week, 2, ceiling), ifelse(Max_change_week <= 50, round_any(Max_change_week, 5, ceiling), round_any(Max_change_week, 10, ceiling))))) %>%
#     toJSON() %>%
#     write_lines(paste0(output_directory_x,'/utla_growth_limits_complete_date.json'))
growth_rate_utla %>%
filter(Date >= '2020-09-01') %>%
select(Date) %>%
unique() %>%
arrange(Date) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/growth_limits_dates.json'))
# age specific rates ####
mye_ages <- read_csv('https://www.nomisweb.co.uk/api/v01/dataset/NM_2002_1.data.csv?geography=2092957699,2013265921...2013265932,1816133633...1816133848,1820327937...1820328318&date=latest&gender=0&c_age=1,3...18,210&measures=20100&select=geography_name,geography_code,c_age_name,obs_value,geography_type') %>%
rename(Population = OBS_VALUE,
Code = GEOGRAPHY_CODE,
Name = GEOGRAPHY_NAME,
Type = GEOGRAPHY_TYPE,
Age = C_AGE_NAME) %>%
group_by(Code, Name, Age) %>%
mutate(Count = n()) %>%
unique() %>%
mutate(Type = ifelse(Count == 2, 'Unitary Authoritory', ifelse(Type == 'local authorities: county / unitary (as of April 2019)', 'Upper Tier Local Authority', ifelse(Type == 'local authorities: district / unitary (as of April 2019)', 'Lower Tier Local Authority', ifelse(Type == 'regions', 'Region', ifelse(Type == 'countries', 'Country', Type)))))) %>%
group_by(Name, Code) %>%
ungroup() %>%
select(-Count) %>%
unique() %>%
mutate(Age = gsub('Aged ', '', Age)) %>%
mutate(Age = gsub('Age', '', Age)) %>%
mutate(Age = gsub(' 0 - ', '0-', Age)) %>%
mutate(Age = paste0(Age, ' years')) %>%
mutate(Age = ifelse(Age %in% c('80-84 years', '85+ years'), '80+ years', Age)) %>%
group_by(Name, Code, Age, Type) %>%
summarise(Population = sum(Population, na.rm = TRUE)) %>%
ungroup()
# We need to back fill the missing days!! #####
age_spec <- read_csv('https://coronavirus.data.gov.uk/downloads/demographic/cases/specimenDate_ageDemographic-unstacked.csv') %>%
filter(areaName %in% c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East', 'England')) %>%
select(areaCode, areaName, areaType, date, `newCasesBySpecimenDate-0_4`,`newCasesBySpecimenDate-5_9`,`newCasesBySpecimenDate-10_14`,`newCasesBySpecimenDate-15_19`,`newCasesBySpecimenDate-20_24`,`newCasesBySpecimenDate-25_29`,`newCasesBySpecimenDate-30_34`,`newCasesBySpecimenDate-35_39`,`newCasesBySpecimenDate-40_44`,`newCasesBySpecimenDate-45_49`,`newCasesBySpecimenDate-50_54`,`newCasesBySpecimenDate-55_59`,`newCasesBySpecimenDate-60_64`,`newCasesBySpecimenDate-65_69`,`newCasesBySpecimenDate-70_74`,`newCasesBySpecimenDate-75_79`,`newCasesBySpecimenDate-80_84`,`newCasesBySpecimenDate-85_89`,`newCasesBySpecimenDate-90+`,`newCasesBySpecimenDate-unassigned`) %>%
pivot_longer(cols = c(`newCasesBySpecimenDate-0_4`,`newCasesBySpecimenDate-5_9`,`newCasesBySpecimenDate-10_14`,`newCasesBySpecimenDate-15_19`,`newCasesBySpecimenDate-20_24`,`newCasesBySpecimenDate-25_29`,`newCasesBySpecimenDate-30_34`,`newCasesBySpecimenDate-35_39`,`newCasesBySpecimenDate-40_44`,`newCasesBySpecimenDate-45_49`,`newCasesBySpecimenDate-50_54`,`newCasesBySpecimenDate-55_59`,`newCasesBySpecimenDate-60_64`,`newCasesBySpecimenDate-65_69`,`newCasesBySpecimenDate-70_74`,`newCasesBySpecimenDate-75_79`,`newCasesBySpecimenDate-80_84`,`newCasesBySpecimenDate-85_89`,`newCasesBySpecimenDate-90+`,`newCasesBySpecimenDate-unassigned`),
names_to = 'Age') %>%
mutate(Age = gsub('newCasesBySpecimenDate-', '', Age)) %>%
mutate(Age = ifelse(Age == 'unassigned', 'Unknown', paste0(Age, ' years'))) %>%
mutate(Age = gsub('_', '-', Age)) %>%
mutate(Age = ifelse(Age %in% c('80-84 years', '85-89 years', '90+ years'), '80+ years', Age)) %>%
filter(areaType != 'overview') %>%
mutate(areaType = ifelse(areaType == 'ltla', 'Lower Tier Local Authority', ifelse(areaType == 'utla', 'Upper Tier Local Authority', ifelse(areaType == 'region', 'Region', ifelse(areaType == 'nation' , 'Nation', NA))))) %>%
rename(Name = areaName,
Code = areaCode,
Type = areaType,
Cases = value,
Date = date) %>%
group_by(Name, Age, Date) %>%
summarise(Cases = sum(Cases, na.rm = TRUE))
Areas <- c('Adur', 'Arun', 'Chichester','Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East', 'England')
Ages <- data.frame(Age = c('0-4 years', '5-9 years', '10-14 years', '15-19 years', '20-24 years' , '25-29 years', '30-34 years', '35-39 years', '40-44 years', '45-49 years', '50-54 years' ,'55-59 years', '60-64 years' , '65-69 years', '70-74 years', '75-79 years', '80+ years'))
Dates <- seq.Date(min(age_spec$Date), max(age_spec$Date), by = '1 day')
age_df_daily_combined <- data.frame(Name = character(), Age = character(), Date = character())
for(i in 1:length(Areas)){
area_x = Areas[i]
df_x <- data.frame(Age = rep(Ages$Age, length(Dates))) %>%
arrange(Age) %>%
group_by(Age) %>%
mutate(Date = seq.Date(min(age_spec$Date), max(age_spec$Date), by = '1 day')) %>%
mutate(Name = area_x) %>%
mutate(Date = as.character(Date)) %>%
ungroup()
age_df_daily_combined <- age_df_daily_combined %>%
bind_rows(df_x)
}
case_age_df_daily <- age_df_daily_combined %>%
mutate(Date = as.Date(Date)) %>%
left_join(age_spec, by = c('Name', 'Date', 'Age')) %>%
mutate(Cases = replace_na(Cases, 0)) %>%
group_by(Name, Age) %>%
arrange(Name, Age, Date) %>%
ungroup() %>%
left_join(mye_ages, by = c('Name', 'Age')) %>%
group_by(Name, Age) %>%
arrange(Name, Age, Date) %>%
mutate(Cumulative_cases = cumsum(Cases)) %>%
mutate(Rolling_7_day_new_cases = rollapply(Cases, 7, sum, align = 'right', fill = NA, partial = TRUE)) %>%
mutate(Rolling_7_day_new_cases = replace_na(Rolling_7_day_new_cases, 0)) %>%
mutate(Perc_change_on_rolling_7_days_actual = round((Rolling_7_day_new_cases - lag(Rolling_7_day_new_cases, 7))/ lag(Rolling_7_day_new_cases, 7), 2)) %>%
mutate(Perc_change_on_rolling_7_days_tidy = factor(ifelse(Rolling_7_day_new_cases == 0 & lag(Rolling_7_day_new_cases, 7) == 0, 'No change (zero cases)', ifelse(Perc_change_on_rolling_7_days_actual == Inf, '0 cases in previous 7 days', ifelse(Perc_change_on_rolling_7_days_actual == -1, '100% fewer cases (now zero cases in recent period)', ifelse(Perc_change_on_rolling_7_days_actual <= -.5, '50%+ fewer cases', ifelse(Perc_change_on_rolling_7_days_actual <= -.5, '50% fewer cases', ifelse(Perc_change_on_rolling_7_days_actual < 0, 'Up to 50% fewer cases', ifelse(Perc_change_on_rolling_7_days_actual == 0, 'No change', ifelse(Perc_change_on_rolling_7_days_actual > 0  & Perc_change_on_rolling_7_days_actual <= .5, 'Up to 50% more cases', ifelse(Perc_change_on_rolling_7_days_actual > .5 & Perc_change_on_rolling_7_days_actual <= 1, 'Up to 100% more cases (double the cases from the previous 7 days)', ifelse(Perc_change_on_rolling_7_days_actual > 1 & Perc_change_on_rolling_7_days_actual <= 2, 'Up to 200% more cases (3x the cases in previous 7 days)', ifelse(Perc_change_on_rolling_7_days_actual > 2 & Perc_change_on_rolling_7_days_actual <= 5, 'Up to 5x the cases in previous 7 days', 'More than 5x the cases in the previous 7 days'))))))))))), levels = c("No change (zero cases)", "100% fewer cases (now zero cases in recent period)",   "50%+ fewer cases" ,  "Up to 50% fewer cases" ,  "No change" ,   "Up to 50% more cases" ,      "Up to 100% more cases (double the cases from the previous 7 days)", "Up to 200% more cases (3x the cases in previous 7 days)","Up to 5x the cases in previous 7 days", "More than 5x the cases in the previous 7 days", "0 cases in previous 7 days"))) %>%
mutate(Change_actual_by_week = ifelse(Perc_change_on_rolling_7_days_tidy == 'No change (zero cases)', 0, ifelse(Perc_change_on_rolling_7_days_tidy == '0 cases in previous 7 days', 1, Perc_change_on_rolling_7_days_actual))) %>%
ungroup() %>%
mutate(ASR = pois.exact(Rolling_7_day_new_cases, Population)[[3]]*100000)
# case_age_df_daily %>%
#   filter(Name == 'West Sussex') %>%
#   View()
case_age_df_daily %>%
ungroup() %>%
filter(Date %in% seq.Date(complete_date -(52*7), complete_date, by = 14)) %>%
arrange(Date) %>%
mutate(Date_label = format(Date, '%d %b')) %>%
select(Date_label) %>%
unique() %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/age_specific_rate_dates.json'))
age_spec_10 <- case_age_df_daily %>%
mutate(Age = ifelse(Age %in% c('0-4 years', '5-9 years'), '0-9 years', ifelse(Age %in% c('10-14 years', '15-19 years'), '10-19 years',ifelse(Age %in% c('20-24 years', '25-29 years'), '20-29 years',ifelse(Age %in% c('30-34 years', '35-39 years'), '30-39 years',ifelse(Age %in% c('40-44 years', '45-49 years'), '40-49 years',ifelse(Age %in% c('50-54 years', '55-59 years'), '50-59 years',ifelse(Age %in% c('60-64 years', '65-69 years'), '60-69 years',ifelse(Age %in% c('70-74 years', '75-79 years'), '70-79 years', '80+ years'))))))))) %>%
group_by(Name, Age, Date) %>%
summarise(Cases = sum(Cases, na.rm = TRUE),
Population = sum(Population, na.rm = TRUE)) %>%
group_by(Name, Age) %>%
arrange(Name, Age, Date) %>%
mutate(Cumulative_cases = cumsum(Cases)) %>%
mutate(Rolling_7_day_new_cases = rollapply(Cases, 7, sum, align = 'right', fill = NA, partial = TRUE)) %>%
mutate(Rolling_7_day_new_cases = replace_na(Rolling_7_day_new_cases, 0)) %>%
mutate(Perc_change_on_rolling_7_days_actual = round((Rolling_7_day_new_cases - lag(Rolling_7_day_new_cases, 7))/ lag(Rolling_7_day_new_cases, 7), 2)) %>%
mutate(Perc_change_on_rolling_7_days_tidy = factor(ifelse(Rolling_7_day_new_cases == 0 & lag(Rolling_7_day_new_cases, 7) == 0, 'No change (zero cases)', ifelse(Perc_change_on_rolling_7_days_actual == Inf, '0 cases in previous 7 days', ifelse(Perc_change_on_rolling_7_days_actual == -1, '100% fewer cases (now zero cases in recent period)', ifelse(Perc_change_on_rolling_7_days_actual <= -.5, '50%+ fewer cases', ifelse(Perc_change_on_rolling_7_days_actual <= -.5, '50% fewer cases', ifelse(Perc_change_on_rolling_7_days_actual < 0, 'Up to 50% fewer cases', ifelse(Perc_change_on_rolling_7_days_actual == 0, 'No change', ifelse(Perc_change_on_rolling_7_days_actual > 0  & Perc_change_on_rolling_7_days_actual <= .5, 'Up to 50% more cases', ifelse(Perc_change_on_rolling_7_days_actual > .5 & Perc_change_on_rolling_7_days_actual <= 1, 'Up to 100% more cases (double the cases from the previous 7 days)', ifelse(Perc_change_on_rolling_7_days_actual > 1 & Perc_change_on_rolling_7_days_actual <= 2, 'Up to 200% more cases (3x the cases in previous 7 days)', ifelse(Perc_change_on_rolling_7_days_actual > 2 & Perc_change_on_rolling_7_days_actual <= 5, 'Up to 5x the cases in previous 7 days', 'More than 5x the cases in the previous 7 days'))))))))))), levels = c("No change (zero cases)", "100% fewer cases (now zero cases in recent period)",   "50%+ fewer cases" ,  "Up to 50% fewer cases" ,  "No change" ,   "Up to 50% more cases" ,      "Up to 100% more cases (double the cases from the previous 7 days)", "Up to 200% more cases (3x the cases in previous 7 days)","Up to 5x the cases in previous 7 days", "More than 5x the cases in the previous 7 days", "0 cases in previous 7 days"))) %>%
mutate(Change_actual_by_week = ifelse(Perc_change_on_rolling_7_days_tidy == 'No change (zero cases)', 0, ifelse(Perc_change_on_rolling_7_days_tidy == '0 cases in previous 7 days', 1, Perc_change_on_rolling_7_days_actual))) %>%
ungroup() %>%
mutate(ASR = pois.exact(Rolling_7_day_new_cases, Population)[[3]]*100000) %>%
mutate(Date_label = format(Date, '%d %b')) %>%
arrange(Date) %>%
select(Name, Age, Date_label, Cases, Cumulative_cases, Rolling_7_day_new_cases, Change_actual_by_week, ASR) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/age_specific_rates_10_years_by_date.json'))
case_age_df_daily %>%
filter(Age %in% c('0-4 years', '5-9 years', '10-14 years', '15-19 years', '20-24 years', '25-29 years')) %>%
mutate(Date_label = format(Date, '%d %b')) %>%
select(Name, Age, Date_label, Cases, Cumulative_cases, Rolling_7_day_new_cases, Change_actual_by_week, ASR) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/age_specific_rates_u30_by_date.json'))
case_age_df_daily %>%
filter(Age %in% c('60-64 years', '65-69 years', '70-74 years', '75-79 years', '80+ years')) %>%
mutate(Age = '60+ years') %>%
group_by(Name, Age, Date) %>%
summarise(Cases = sum(Cases, na.rm = TRUE),
Population = sum(Population, na.rm = TRUE)) %>%
group_by(Name) %>%
arrange(Name, Age, Date) %>%
mutate(Cumulative_cases = cumsum(Cases)) %>%
mutate(Rolling_7_day_new_cases = rollapply(Cases, 7, sum, align = 'right', fill = NA, partial = TRUE)) %>%
mutate(Rolling_7_day_new_cases = replace_na(Rolling_7_day_new_cases, 0)) %>%
mutate(Perc_change_on_rolling_7_days_actual = round((Rolling_7_day_new_cases - lag(Rolling_7_day_new_cases, 7))/ lag(Rolling_7_day_new_cases, 7), 2)) %>%
mutate(Perc_change_on_rolling_7_days_tidy = factor(ifelse(Rolling_7_day_new_cases == 0 & lag(Rolling_7_day_new_cases, 7) == 0, 'No change (zero cases)', ifelse(Perc_change_on_rolling_7_days_actual == Inf, '0 cases in previous 7 days', ifelse(Perc_change_on_rolling_7_days_actual == -1, '100% fewer cases (now zero cases in recent period)', ifelse(Perc_change_on_rolling_7_days_actual <= -.5, '50%+ fewer cases', ifelse(Perc_change_on_rolling_7_days_actual <= -.5, '50% fewer cases', ifelse(Perc_change_on_rolling_7_days_actual < 0, 'Up to 50% fewer cases', ifelse(Perc_change_on_rolling_7_days_actual == 0, 'No change', ifelse(Perc_change_on_rolling_7_days_actual > 0  & Perc_change_on_rolling_7_days_actual <= .5, 'Up to 50% more cases', ifelse(Perc_change_on_rolling_7_days_actual > .5 & Perc_change_on_rolling_7_days_actual <= 1, 'Up to 100% more cases (double the cases from the previous 7 days)', ifelse(Perc_change_on_rolling_7_days_actual > 1 & Perc_change_on_rolling_7_days_actual <= 2, 'Up to 200% more cases (3x the cases in previous 7 days)', ifelse(Perc_change_on_rolling_7_days_actual > 2 & Perc_change_on_rolling_7_days_actual <= 5, 'Up to 5x the cases in previous 7 days', 'More than 5x the cases in the previous 7 days'))))))))))), levels = c("No change (zero cases)", "100% fewer cases (now zero cases in recent period)",   "50%+ fewer cases" ,  "Up to 50% fewer cases" ,  "No change" ,   "Up to 50% more cases" ,      "Up to 100% more cases (double the cases from the previous 7 days)", "Up to 200% more cases (3x the cases in previous 7 days)","Up to 5x the cases in previous 7 days", "More than 5x the cases in the previous 7 days", "0 cases in previous 7 days"))) %>%
mutate(Change_actual_by_week = ifelse(Perc_change_on_rolling_7_days_tidy == 'No change (zero cases)', 0, ifelse(Perc_change_on_rolling_7_days_tidy == '0 cases in previous 7 days', 1, Perc_change_on_rolling_7_days_actual))) %>%
ungroup() %>%
mutate(ASR = pois.exact(Rolling_7_day_new_cases, Population)[[3]]*100000) %>%
mutate(Date_label = format(Date, '%d %b')) %>%
select(Name, Age, Date_label, Cases, Cumulative_cases, Rolling_7_day_new_cases, Change_actual_by_week, ASR) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/age_specific_rates_60_plus_by_date.json'))
# case_age_df_daily %>%
#   mutate(Age = ifelse(Age %in% c('0-4 years', '5-9 years'), '0-9 years', ifelse(Age %in% c('10-14 years', '15-19 years'), '10-19 years',ifelse(Age %in% c('20-24 years', '25-29 years'), '20-29 years',ifelse(Age %in% c('30-34 years', '35-39 years'), '30-39 years',ifelse(Age %in% c('40-44 years', '45-49 years'), '40-49 years',ifelse(Age %in% c('50-54 years', '55-59 years'), '50-59 years',ifelse(Age %in% c('60-64 years', '65-69 years'), '60-69 years',ifelse(Age %in% c('70-74 years', '75-79 years'), '70-79 years', '80+ years'))))))))) %>%
#   select(Age) %>%
#   unique()
# MSOA map ####
if(!file.exists(paste0(github_repo_dir, '/Source files/msoa_lookup_local.csv'))) {
oa_region <- read_csv('https://opendata.arcgis.com/datasets/180c271e84fc400d92ca6dcc7f6ff780_0.csv') %>%
select(OA11CD, RGN11NM)
msoa_names <- read_csv('https://visual.parliament.uk/msoanames/static/MSOA-Names-1.8.csv') %>%
select(msoa11cd, msoa11hclnm) %>%
rename(MSOA11CD = msoa11cd)
msoa_lookup <- read_csv('https://opendata.arcgis.com/datasets/6ecda95a83304543bc8feedbd1a58303_0.csv') %>%
left_join(read_csv('https://opendata.arcgis.com/datasets/180c271e84fc400d92ca6dcc7f6ff780_0.csv')[c('OA11CD', 'RGN11NM')], by = 'OA11CD') %>%
select(MSOA11CD, MSOA11NM, LAD11NM, RGN11NM) %>%
unique() %>%
left_join(msoa_names, by = 'MSOA11CD')
lsoa_to_msoa <- read_csv('https://opendata.arcgis.com/datasets/a46c859088a94898a7c462eeffa0f31a_0.csv') %>%
select(LSOA11CD, MSOA11CD, MSOA11NM) %>%
unique()
msoa_to_utla <- read_csv('https://opendata.arcgis.com/datasets/4c6f3314565e43c5ac7885fd71347548_0.csv') %>%
left_join(lsoa_to_msoa, by = 'LSOA11CD') %>%
select(MSOA11CD, UTLA19NM) %>%
mutate(UTLA19NM = ifelse(UTLA19NM %in% c('City of London', 'Hackney'), 'Hackney and City of London', ifelse(UTLA19NM %in% c('Cornwall', 'Isles of Scilly'), 'Cornwall and Isles of Scilly', UTLA19NM))) %>%
filter(!is.na(MSOA11CD)) %>%
unique()
msoa_lookup %>%
left_join(msoa_to_utla, by = 'MSOA11CD') %>%
write.csv(., paste0(github_repo_dir, '/Source files/msoa_lookup_local.csv'), row.names = FALSE)
}
msoa_lookup <- read_csv(paste0(github_repo_dir, '/Source files/msoa_lookup_local.csv'))
se_msoas <- msoa_lookup %>%
filter(RGN11NM == 'South East')
wsx_msoas <- msoa_lookup %>%
filter(LAD11NM %in% c('Adur', 'Arun', 'Chichester','Crawley', 'Horsham', 'Mid Sussex', 'Worthing'))
# Weekly rolling sums and population-based rates of new cases by specimen date time series data are available to download for English MSOAs via the following links. The data are updated each day, and show the latest 7 days for which near-complete data release date minus 5 days are available, and historic non-overlapping 7-day blocks. Dates are the final day in the relevant 7-day block, and counts between 0 and 2 are blank in the CSV or NULL in the other formats.
msoa_cases_1 <-read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=msoa&metric=newCasesBySpecimenDateRollingSum&metric=newCasesBySpecimenDateRollingRate&format=csv') %>%
select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum, newCasesBySpecimenDateRollingRate) %>%
# filter(areaCode %in% msoa_lookup$MSOA11CD) %>%
filter(date %in% c(max(date))) %>%
select(areaCode, date, newCasesBySpecimenDateRollingRate) %>%
rename(Latest_rate = newCasesBySpecimenDateRollingRate) %>%
mutate(Latest_rate_key = factor(ifelse(is.na(Latest_rate), 'Less than 3 cases', ifelse(Latest_rate <= 50, 'Up to 50 per 100,000', ifelse(Latest_rate <= 100, '51-100 cases per 100,000', ifelse(Latest_rate <= 150, '101-150 cases per 100,000', ifelse(Latest_rate <= 200, '151-200 cases per 100,000', 'More than 200 cases per 100,000'))))), levels = c('Less than 3 cases', 'Up to 50 cases per 100,000', '51-100 cases per 100,000', '101-150 cases per 100,000', '151-200 cases per 100,000', 'More than 200 cases per 100,000')))
msoa_cases_raw <- as.data.frame(read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=msoa&metric=newCasesBySpecimenDateRollingSum&metric=newCasesBySpecimenDateRollingRate&format=csv') %>%
select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum, newCasesBySpecimenDateRollingRate) %>%
# filter(areaCode %in% msoa_lookup$MSOA11CD) %>%
group_by(areaCode, areaName) %>%
arrange(areaCode, areaName, date) %>%
filter(date %in% c(max(date), max(date) - 7)) %>%
select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum) %>%
mutate(date = ifelse(date == max(date), 'This_week', ifelse(date == max(date)-7, 'Last_week', NA))) %>%
pivot_wider(names_from = 'date', values_from = 'newCasesBySpecimenDateRollingSum') %>%
mutate(Change_actual = This_week - Last_week) %>%
mutate(Change_label = ifelse(is.na(Last_week) & is.na(This_week), 'Cases below 3 in both weeks', ifelse(is.na(Last_week), 'Cases below 3 in previous week but have risen', ifelse(is.na(This_week), 'Cases below 3 in the latest 7 days but have fallen', ifelse(Change_actual == 0, 'No change in case numbers', ifelse(Change_actual < 0, 'Cases have fallen', ifelse(Change_actual>0, 'Cases have risen', NA))))))) %>%
mutate(Case_key = ifelse(is.na(This_week), '0-2 cases', ifelse(This_week <= 5, '3-5 cases', ifelse(This_week <= 10, '6-10 cases', ifelse(This_week <= 20, '11-20 cases', ifelse(This_week <= 30, '21-30 cases', ifelse(This_week <= 40, '31-40 cases',ifelse(This_week <= 50, '41-50 cases','More than 50 cases')))))))) %>%
left_join(msoa_cases_1, by = 'areaCode') %>%
left_join(msoa_lookup, by = c('areaCode' = 'MSOA11CD')) %>%
mutate(Label = paste0('<b>', MSOA11NM,' (', msoa11hclnm,')</b><br><br>In the seven days to ', format(date, '%A %d %B'), ' there were ', ifelse(is.na(This_week), ' less than three new cases.', paste0(format(This_week, big.mark = ',', trim = TRUE), ' new cases, this is a rate of ', round(Latest_rate, 1), ' cases per 100,000 population.')), '<br><br>', ifelse(is.na(Last_week) & is.na(This_week), 'Cases have been below 3 in the last two 7 day periods.', ifelse(is.na(Last_week), paste0('Cases were below 3 in the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,') but have risen this week.'), ifelse(is.na(This_week), paste0('Cases are now below 3 in the latest 7 days but have fallen since the previous 7 day period (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual == 0, 'There is no change in case numbers over the last two weeks', ifelse(Change_actual < 0, paste0('Cases have fallen in the last 7 days compared to the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual >0, paste0('Cases have risen in the last 7 days compared to the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,').'), NA)))))))) %>%
ungroup())
msoa_cases <- msoa_cases_raw %>%
select(MSOA11NM, Case_key, Latest_rate_key, Change_label, Label) %>%
#  filter(MSOA11NM %in% se_msoas$MSOA11NM) %>%
arrange(MSOA11NM)
msoa_boundaries_json <- geojson_read("https://opendata.arcgis.com/datasets/23cdb60ee47e4fef8d72e4ee202accb0_0.geojson",  what = "sp") %>%
filter(MSOA11NM %in% msoa_cases$MSOA11NM) %>%
arrange(MSOA11NM)
df <- data.frame(ID = character())
# Get the IDs of spatial polygon
for (i in msoa_boundaries_json@polygons ) { df <- rbind(df, data.frame(ID = i@ID, stringsAsFactors = FALSE))  }
# and set rowname = ID
row.names(msoa_cases) <- df$ID
# Then use df as the second argument to the spatial dataframe conversion function:
msoa_boundaries_json <- SpatialPolygonsDataFrame(msoa_boundaries_json, msoa_cases)
# geojson_write(ms_simplify(geojson_json(utla_ua_boundaries_rate_geo), keep = 0.2), file = paste0(output_directory_x, '/utla_covid_rate_latest.geojson'))
geojson_write(ms_simplify(geojson_json(msoa_boundaries_json), keep = 0.2), file = paste0(output_directory_x, '/msoa_covid_rate_latest.geojson'))
msoa_cases_raw %>%
select(MSOA11NM, msoa11hclnm, Latest_rate, LAD11NM, This_week, Last_week, Change_label, date, Change_actual) %>%
mutate(Change_label = paste0(ifelse(is.na(Last_week) & is.na(This_week), 'Cases have been below 3 in the last two 7 day periods.', ifelse(is.na(Last_week), paste0('Cases were below 3 in the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,') but have risen this week.'), ifelse(is.na(This_week), paste0('Cases are now below 3 in the latest 7 days but have fallen since the previous 7 day period (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual == 0, 'There is no change in case numbers over the last two weeks', ifelse(Change_actual < 0, paste0('<b class = "cases_go_down">', Change_actual, '</b> cases compared to the previous 7 days (', Last_week,  ' cases in the 7 days to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual >0, paste0('<b class = "cases_go_up">+', Change_actual, '</b> cases compared to the previous 7 days (', Last_week, ' cases in the 7 days to ', format(max(date)-7, '%A %d %B') ,').'), NA)))))))) %>%
mutate(This_week = ifelse(is.na(This_week), '0-2', format(This_week, big.mark = ',', trim = TRUE)),
Last_week = ifelse(is.na(Last_week), '0-2', format(Last_week, big.mark = ',', trim = TRUE)),
Latest_rate = ifelse(is.na(Latest_rate), 'No rate available', Latest_rate)) %>%
select(!c('date', 'Change_actual')) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/msoa_summary.json'))
#
# # MSOA map ####
# oa_region <- read_csv('https://opendata.arcgis.com/datasets/180c271e84fc400d92ca6dcc7f6ff780_0.csv')[c('OA11CD', 'RGN11MM')]
#
# msoa_names <- read_csv('https://visual.parliament.uk/msoanames/static/MSOA-Names-1.8.csv') %>%
#   select(msoa11cd, msoa11hclnm) %>%
#   rename(MSOA11CD = msoa11cd)
#
#
# if(exists('msoa_names') == FALSE) {
#   msoa_names <- read_csv(paste0(github_repo_dir,'/Source files/msoa_names_backup.csv'))
# }
#
# msoa_names %>%
#   write.csv(., paste0(github_repo_dir, '/Source files/msoa_names_backup.csv'), row.names = FALSE)
#
# msoa_lookup <- read_csv('https://opendata.arcgis.com/datasets/6ecda95a83304543bc8feedbd1a58303_0.csv') %>%
#   left_join(read_csv('https://opendata.arcgis.com/datasets/180c271e84fc400d92ca6dcc7f6ff780_0.csv')[c('OA11CD', 'RGN11NM')], by = 'OA11CD') %>%
#   select(MSOA11CD, MSOA11NM, LAD11NM, RGN11NM) %>%
#   unique() %>%
#   left_join(msoa_names, by = 'MSOA11CD')
#
# if(exists('msoa_lookup') == FALSE) {
#   msoa_lookup <- read_csv(paste0(github_repo_dir,'/Source files/msoa_lookup_backup.csv'))
# }
#
# msoa_lookup %>%
#   write.csv(., paste0(github_repo_dir, '/Source files/msoa_lookup_backup.csv'), row.names = FALSE)
#
# se_msoas <- msoa_lookup %>%
#   filter(RGN11NM == 'South East')
#
# wsx_msoas <- msoa_lookup %>%
#   filter(LAD11NM %in% c('Adur', 'Arun', 'Chichester','Crawley', 'Horsham', 'Mid Sussex', 'Worthing'))
#
#
# # Weekly rolling sums and population-based rates of new cases by specimen date time series data are available to download for English MSOAs via the following links. The data are updated each day, and show the latest 7 days for which near-complete data release date minus 5 days are available, and historic non-overlapping 7-day blocks. Dates are the final day in the relevant 7-day block, and counts between 0 and 2 are blank in the CSV or NULL in the other formats.
#
#
# msoa_cases_1 <- read_csv('https://coronavirus.data.gov.uk/downloads/msoa_data/MSOAs_latest.csv') %>%
#   # filter(areaCode %in% msoa_lookup$MSOA11CD) %>%
#   filter(date %in% c(max(date))) %>%
#   select(areaCode, date, newCasesBySpecimenDateRollingRate) %>%
#   rename(Latest_rate = newCasesBySpecimenDateRollingRate) %>%
#   mutate(Latest_rate_key = factor(ifelse(is.na(Latest_rate), 'Less than 3 cases', ifelse(Latest_rate <= 50, 'Up to 50 per 100,000', ifelse(Latest_rate <= 100, '51-100 cases per 100,000', ifelse(Latest_rate <= 150, '101-150 cases per 100,000', ifelse(Latest_rate <= 200, '151-200 cases per 100,000', 'More than 200 cases per 100,000'))))), levels = c('Less than 3 cases', 'Up to 50 cases per 100,000', '51-100 cases per 100,000', '101-150 cases per 100,000', '151-200 cases per 100,000', 'More than 200 cases per 100,000')))
#
# msoa_cases_raw <- as.data.frame(read_csv('https://coronavirus.data.gov.uk/downloads/msoa_data/MSOAs_latest.csv') %>%
#   # filter(areaCode %in% msoa_lookup$MSOA11CD) %>%
#   group_by(areaCode, areaName) %>%
#   arrange(areaCode, areaName, date) %>%
#   filter(date %in% c(max(date), max(date) - 7)) %>%
#   select(areaCode, areaName, date, newCasesBySpecimenDateRollingSum) %>%
#   mutate(date = ifelse(date == max(date), 'This_week', ifelse(date == max(date)-7, 'Last_week', NA))) %>%
#   pivot_wider(names_from = 'date', values_from = 'newCasesBySpecimenDateRollingSum') %>%
#   mutate(Change_actual = This_week - Last_week) %>%
#   mutate(Change_label = ifelse(is.na(Last_week) & is.na(This_week), 'Cases below 3 in both weeks', ifelse(is.na(Last_week), 'Cases below 3 in previous week but have risen', ifelse(is.na(This_week), 'Cases below 3 in the latest 7 days but have fallen', ifelse(Change_actual == 0, 'No change in case numbers', ifelse(Change_actual < 0, 'Cases have fallen', ifelse(Change_actual>0, 'Cases have risen', NA))))))) %>%
#   mutate(Case_key = ifelse(is.na(This_week), '0-2 cases', ifelse(This_week <= 5, '3-5 cases', ifelse(This_week <= 10, '6-10 cases', ifelse(This_week <= 15, '11-15 cases', 'More than 15 cases'))))) %>%
#   left_join(msoa_cases_1, by = 'areaCode') %>%
#   left_join(msoa_lookup, by = c('areaCode' = 'MSOA11CD')) %>%
#   mutate(Label = paste0('<b>', MSOA11NM,' (', msoa11hclnm,')</b><br><br>In the seven days to ', format(date, '%A %d %B'), ' there were ', ifelse(is.na(This_week), ' less than three new cases.', paste0(format(This_week, big.mark = ',', trim = TRUE), ' new cases, this is a rate of ', round(Latest_rate, 1), ' cases per 100,000 population.')), '<br><br>', ifelse(is.na(Last_week) & is.na(This_week), 'Cases have been below 3 in the last two 7 day periods.', ifelse(is.na(Last_week), paste0('Cases were below 3 in the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,') but have risen this week.'), ifelse(is.na(This_week), paste0('Cases are now below 3 in the latest 7 days but have fallen since the previous 7 day period (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual == 0, 'There is no change in case numbers over the last two weeks', ifelse(Change_actual < 0, paste0('Cases have fallen in the last 7 days compared to the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual >0, paste0('Cases have risen in the last 7 days compared to the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,').'), NA)))))))) %>%
#   ungroup())
#
# msoa_cases <- msoa_cases_raw %>%
#   select(MSOA11NM, Case_key, Latest_rate_key, Change_label, Label) %>%
#   filter(MSOA11NM %in% se_msoas$MSOA11NM) %>%
#   arrange(MSOA11NM)
#
# msoa_boundaries_json <- geojson_read("https://opendata.arcgis.com/datasets/23cdb60ee47e4fef8d72e4ee202accb0_0.geojson",  what = "sp") %>%
#   filter(MSOA11NM %in% se_msoas$MSOA11NM) %>%
#   arrange(MSOA11NM)
#
# df <- data.frame(ID = character())
#
# # Get the IDs of spatial polygon
# for (i in msoa_boundaries_json@polygons ) { df <- rbind(df, data.frame(ID = i@ID, stringsAsFactors = FALSE))  }
#
# # and set rowname = ID
# row.names(msoa_cases) <- df$ID
#
# # Then use df as the second argument to the spatial dataframe conversion function:
# msoa_boundaries_json <- SpatialPolygonsDataFrame(msoa_boundaries_json, msoa_cases)
#
#
# # geojson_write(ms_simplify(geojson_json(utla_ua_boundaries_rate_geo), keep = 0.2), file = paste0(output_directory_x, '/utla_covid_rate_latest.geojson'))
#
# geojson_write(geojson_json(msoa_boundaries_json), file = paste0(output_directory_x, '/msoa_covid_rate_latest.geojson'))
#
# msoa_cases_raw %>%
#   select(MSOA11NM, msoa11hclnm, Latest_rate,  This_week, Last_week, Change_label, date, Change_actual) %>%
#   mutate(Change_label = paste0(ifelse(is.na(Last_week) & is.na(This_week), 'Cases have been below 3 in the last two 7 day periods.', ifelse(is.na(Last_week), paste0('Cases were below 3 in the previous 7 days (up to ', format(max(date)-7, '%A %d %B') ,') but have risen this week.'), ifelse(is.na(This_week), paste0('Cases are now below 3 in the latest 7 days but have fallen since the previous 7 day period (up to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual == 0, 'There is no change in case numbers over the last two weeks', ifelse(Change_actual < 0, paste0('<b class = "cases_go_down">', Change_actual, '</b> cases compared to the previous 7 days (', Last_week,  ' cases in the 7 days to ', format(max(date)-7, '%A %d %B') ,').'), ifelse(Change_actual >0, paste0('<b class = "cases_go_up">+', Change_actual, '</b> cases compared to the previous 7 days (', Last_week, ' cases in the 7 days to ', format(max(date)-7, '%A %d %B') ,').'), NA)))))))) %>%
#   mutate(This_week = ifelse(is.na(This_week), '0-2', format(This_week, big.mark = ',', trim = TRUE)),
#          Last_week = ifelse(is.na(Last_week), '0-2', format(Last_week, big.mark = ',', trim = TRUE)),
#          Latest_rate = ifelse(is.na(Latest_rate), 'No rate available', Latest_rate)) %>%
#   select(!c('date', 'Change_actual')) %>%
#   toJSON() %>%
#   write_lines(paste0(output_directory_x,'/msoa_summary.json'))
ltla_summary_1 <- p12_test_df %>%
filter(Type %in% c('Unitary Authority', 'Lower Tier Local Authority')) %>%
filter(Date == last_case_date) %>%
select(Name, Date, Cumulative_cases, Cumulative_per_100000) %>%
rename(Cumulative_date = Date)
ltla_summary_2 <- p12_test_df %>%
filter(Date %in% c(complete_date)) %>%
rename(Rolling_7_day_average_new_cases = Seven_day_average_new_cases) %>%
select(Name, Date, New_cases, New_cases_per_100000, Rolling_7_day_new_cases, Rolling_7_day_new_cases_per_100000, Rolling_7_day_average_new_cases, Perc_change_on_rolling_7_days_actual, Previous_7_days_sum) %>%
mutate(Change_direction = ifelse(Perc_change_on_rolling_7_days_actual <0, 'Down', ifelse(Perc_change_on_rolling_7_days_actual == 0, 'Same', ifelse(Perc_change_on_rolling_7_days_actual > 0, 'Up', NA)))) %>%
rename(Rate_date = Date)
ltla_summary <- ltla_summary_1 %>%
left_join(ltla_summary_2, by = 'Name') %>%
left_join(read_csv(paste0(github_repo_dir, '/Source files/ltla_tiers.csv')), by = 'Name') %>%
mutate(Change_label = ifelse(Change_direction == 'Down', paste0('decreased by ', format(abs(Previous_7_days_sum - Rolling_7_day_new_cases), big.mark = ',', trim = TRUE), ' cases (', round(abs(Perc_change_on_rolling_7_days_actual) * 100,1), '%)'),ifelse(Change_direction == 'Up', paste0('increased by ',   format(abs(Previous_7_days_sum - Rolling_7_day_new_cases), big.mark = ',', trim = TRUE), ' cases (', round(abs(Perc_change_on_rolling_7_days_actual) * 100,1), '%)'), 'stayed the same.')))
ltla_summary %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/ltla_summary.json'))
ltla_boundaries <- geojson_read('https://opendata.arcgis.com/datasets/3a4fa2ce68f642e399b4de07643eeed3_0.geojson',  what = "sp")
#download.file('https://opendata.arcgis.com/datasets/3a4fa2ce68f642e399b4de07643eeed3_0.geojson', paste0(github_repo_dir, '/Source files/failsafe_ltla_boundary.geojson'), mode = 'wb')
if(exists('ltla_boundaries') == FALSE) {
ltla_boundaries <- geojson_read(paste0(github_repo_dir, '/Source files/failsafe_ltla_boundary.geojson'),  what = "sp")
}
# utla_restrictions_geojson <-geojson_read("https://opendata.arcgis.com/datasets/b216b4c8a4e74f6fb692a1785255d777_0.geojson",  what = "sp") %>%
#   filter(substr(ctyua19cd, 1,1 ) == 'E') %>%
#   mutate(ctyua19nm = ifelse(ctyua19nm %in% c('Cornwall', 'Isles of Scilly'), 'Cornwall and Isles of Scilly', ifelse(ctyua19nm %in% c('City of London', 'Hackney'), 'Hackney and City of London', ctyua19nm))) %>%
#   mutate(ctyua19cd = ifelse(ctyua19cd %in% c('E06000053', 'E06000052'), 'E06000052', ifelse(ctyua19cd %in% c('E09000001', 'E09000012'), 'E09000012', ctyua19cd))) %>%
#   group_by(ctyua19cd, ctyua19nm) %>%
#   summarise() %>%
#   arrange(ctyua19cd) %>%
#   left_join(utla_summary, by = c('ctyua19nm' = 'Name'))
# geojson_write(geojson_json(utla_restrictions_geojson), file = paste0(output_directory_x, '/utla_covid_latest.geojson'))
ltla_restrictions_geojson <- ltla_boundaries %>%
filter(lad19cd %in% ltla_summary$`Area code`) %>%
arrange(lad19nm)
ltla_summary <- ltla_summary %>%
arrange(Name)
#left_join(ltla_summary, by = c('lad19nm' = 'Name'))
df <- data.frame(ID = character())
# Get the IDs of spatial polygon
for (i in ltla_restrictions_geojson@polygons ) { df <- rbind(df, data.frame(ID = i@ID, stringsAsFactors = FALSE))  }
# and set rowname = ID
row.names(ltla_summary) <- df$ID
# Then use df as the second argument to the spatial dataframe conversion function:
ltla_restrictions_geojson <- SpatialPolygonsDataFrame(ltla_restrictions_geojson, ltla_summary)
geojson_write(geojson_json(ltla_restrictions_geojson), file = paste0(output_directory_x, '/ltla_covid_latest.geojson'))
# Positivity and tests ####
positivity_ltla <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=ltla&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&metric=newVirus&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_utla <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=utla&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_region <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=region&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_nation <- read_csv('https://api.coronavirus.data.gov.uk/v2/data?areaType=nation&metric=uniquePeopleTestedBySpecimenDateRollingSum&metric=uniqueCasePositivityBySpecimenDateRollingSum&format=csv') %>%
filter(substr(areaCode, 1,1) == 'E') %>%
select(-areaType) %>%
rename(Name = areaName,
Code = areaCode,
Date = date)
positivity_df <- positivity_ltla %>%
bind_rows(positivity_utla) %>%
bind_rows(positivity_region) %>%
bind_rows(positivity_nation) %>%
unique() %>%
filter(Name %in% c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East', 'England')) %>%
mutate(Name = ifelse(Name == 'South East', 'South East region', Name))
positivity_df %>%
filter(Date == complete_date) %>%
mutate(uniquePeopleTestedBySpecimenDateRollingSum = format(uniquePeopleTestedBySpecimenDateRollingSum, big.mark = ',', trim = TRUE)) %>%
mutate(uniqueCasePositivityBySpecimenDateRollingSum = paste0(uniqueCasePositivityBySpecimenDateRollingSum, '%')) %>%
select(Name, uniquePeopleTestedBySpecimenDateRollingSum, uniqueCasePositivityBySpecimenDateRollingSum) %>%
mutate(Name = factor(Name, levels = c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East region', 'England'))) %>%
arrange(Name) %>%
toJSON() %>%
write_lines(paste0(output_directory_x,'/positivity_at_a_glance.json'))
# Polymerase chain reaction (PCR) tests are lab-based and test for the presence of SARS-CoV-2 virus. This data shows the number of people who received a PCR test in the previous 7 days, and the percentage of people who received a PCR test in the previous 7 days who had at least one positive PCR test result.
# If a person has had more than one test result in the 7-day period, they are only counted once. If any of their tests in that period were positive, they count as one person with a positive test result. The positivity percentage is the number of people with a positive test result, divided by the number of people tested and multiplied by 100.
# Individuals tested more than once in the period are only counted once in the denominator, and those with more than one positive test result in the period are only included once in the numerator.
positivity_worked <- positivity_df %>%
rename(Seven_day_PCR_positivity = uniqueCasePositivityBySpecimenDateRollingSum,
Seven_day_PCR_tested_individuals = uniquePeopleTestedBySpecimenDateRollingSum) %>%
group_by(Name) %>%
arrange(Name, Date) %>%
mutate(Perc_change_on_individuals_tested = round((Seven_day_PCR_tested_individuals - lag(Seven_day_PCR_tested_individuals, 7))/ lag(Seven_day_PCR_tested_individuals, 7), 2))  %>%
mutate(Perc_change_on_individuals_tested = ifelse(Perc_change_on_individuals_tested == Inf, 1, Perc_change_on_individuals_tested)) %>%
mutate(Perc_change_on_individuals_tested = replace_na(Perc_change_on_individuals_tested, 0)) %>%
mutate(Name = factor(Name, levels = c('Adur', 'Arun', 'Chichester', 'Crawley', 'Horsham', 'Mid Sussex', 'Worthing', 'West Sussex', 'South East region', 'England'))) %>%
arrange(Name, Date) %>%
filter(Date >= max(Date) - 90)
positivity_worked %>%
filter(Date == complete_date)
positivity_worked %>%
select(!Code) %>%
toJSON() %>%
write_lines(paste0(output_directory_x, '/positivity_df.json'))
library(lemon)
data_dummy_positivity_worked <- positivity_worked %>%
rename(dummy_name = Name)
positivity_worked_plotted <- ggplot(positivity_worked,
aes(x = Date,
y = Seven_day_PCR_positivity,
colour = Name)) +
geom_line(data = data_dummy_positivity_worked,
aes(x = Date,
y = Seven_day_PCR_positivity,
group = dummy_name),
colour = '#dbdbdb',
size = .6) +
geom_line(size = .9) +
geom_point(size = .5) +
ph_theme() +
theme(axis.text.x = element_text(angle = 90, size = 6),
legend.position = 'none') +
scale_y_continuous(labels = label_comma(accuracy = 1, suffix = '%'),
limits = c(0,30),
breaks = seq(0, 30, 5)) +
scale_x_date(date_labels = "%b %d",
breaks = seq.Date(max(positivity_worked$Date) -(52*7), max(positivity_worked$Date), by = 7),
limits = c(min(positivity_worked$Date), max(positivity_worked$Date) + 7),
expand = c(0.01,1)) +
labs(x = '',
y = '7-day rolling PCR case positivity rate',
title = paste0('7-day PCR Case positivity rate for Covid-19 in the last 90 days; West Sussex, South East region, and England'),
subtitle = paste0('Pillar 1 and 2 combined; data as at ', format(last_date, '%d %B %Y')))  +
theme(axis.text.x = element_text(size = 8)) +
facet_rep_wrap(. ~ Name, ncol = 4, repeat.tick.labels = TRUE)
png(paste0(output_directory_x, '/Figure_7_day_rolling_positivity_rates_latest_faceted.png'),
width = 1480,
height = 880,
res = 130)
print(positivity_worked_plotted)
dev.off()
library(easypackages)
libraries("readxl", "readr", "plyr", "dplyr", "ggplot2", "png", "tidyverse", "reshape2", "scales", 'zoo', 'stats',"rgdal", 'rgeos', "tmaptools", 'sp', 'sf', 'maptools', 'leaflet', 'leaflet.extras', 'spdplyr', 'geojsonio', 'rmapshaper', 'jsonlite', 'grid', 'aweek', 'xml2', 'rvest', 'officer', 'flextable', 'viridis', 'epitools')
install.packages(c("rgdal","leaflet.extras","spdplyr","rmapshaper","aweek","officer","flextable"))
libraries("readxl", "readr", "plyr", "dplyr", "ggplot2", "png", "tidyverse", "reshape2", "scales", 'zoo', 'stats',"rgdal", 'rgeos', "tmaptools", 'sp', 'sf', 'maptools', 'leaflet', 'leaflet.extras', 'spdplyr', 'geojsonio', 'rmapshaper', 'jsonlite', 'grid', 'aweek', 'xml2', 'rvest', 'officer', 'flextable', 'viridis', 'epitools')
capwords = function(s, strict = FALSE) {
cap = function(s) paste(toupper(substring(s, 1, 1)),
{s = substring(s, 2); if(strict) tolower(s) else s},sep = "", collapse = " " )
sapply(strsplit(s, split = " "), cap, USE.NAMES = !is.null(names(s)))}
options(scipen = 999)
ph_theme = function(){
theme(
plot.title = element_text(colour = "#000000", face = "bold", size = 10),
plot.subtitle = element_text(colour = "#000000", size = 10),
panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank(),
panel.background = element_rect(fill = "#FFFFFF"),
panel.grid.major.y = element_line(colour = "#E7E7E7", size = .3),
panel.grid.minor.y = element_blank(),
strip.text = element_text(colour = "#000000", size = 10, face = "bold"),
strip.background = element_blank(),
axis.ticks = element_line(colour = "#dbdbdb"),
legend.position = "bottom",
legend.title = element_text(colour = "#000000", size = 9, face = "bold"),
legend.background = element_rect(fill = "#ffffff"),
legend.key = element_rect(fill = "#ffffff", colour = "#ffffff"),
legend.text = element_text(colour = "#000000", size = 9),
axis.text.y = element_text(colour = "#000000", size = 8),
axis.text.x = element_text(colour = "#000000", angle = 0, hjust = 1, vjust = .5, size = 8),
axis.title =  element_text(colour = "#000000", size = 9, face = "bold"),
axis.line = element_line(colour = "#dbdbdb")
)
}
library(easypackages)
libraries("readxl", "readr", "plyr", "dplyr", "ggplot2", "png", "tidyverse", "reshape2", "scales", 'zoo', 'stats',"rgdal", 'rgeos', "tmaptools", 'sp', 'sf', 'maptools', 'leaflet', 'leaflet.extras', 'spdplyr', 'geojsonio', 'rmapshaper', 'jsonlite', 'grid', 'aweek', 'xml2', 'rvest', 'officer', 'flextable', 'viridis', 'epitools')
install.packages("geojsonio")
libraries("readxl", "readr", "plyr", "dplyr", "ggplot2", "png", "tidyverse", "reshape2", "scales", 'zoo', 'stats',"rgdal", 'rgeos', "tmaptools", 'sp', 'sf', 'maptools', 'leaflet', 'leaflet.extras', 'spdplyr', 'geojsonio', 'rmapshaper', 'jsonlite', 'grid', 'aweek', 'xml2', 'rvest', 'officer', 'flextable', 'viridis', 'epitools')
library(sf)
